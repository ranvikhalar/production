{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with parquet files\n",
    "\n",
    "## Objective\n",
    "\n",
    "+ In this assignment, we will use the data downloaded with the module `data_manager` to create features.\n",
    "\n",
    "(11 pts total)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ This notebook assumes that price data is available to you in the environment variable `PRICE_DATA`. If you have not done so, then execute the notebook `01_materials/labs/2_data_engineering.ipynb` to create this data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variables using dotenv. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# Load the dotenv extension\n",
    "%load_ext dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variable `PRICE_DATA`.\n",
    "+ Use [glob](https://docs.python.org/3/library/glob.html) to find the path of all parquet files in the directory `PRICE_DATA`.\n",
    "\n",
    "(1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Load the environment variable PRICE_DATA\n",
    "ft_dir = os.getenv('PRICE_DATA')\n",
    "\n",
    "# If recursive is true, the pattern “**” will match any files and zero or more directories, subdirectories and symbolic links to directories.\n",
    "parquet_files = glob(ft_dir + '**/*.parquet', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ticker and using Dask, do the following:\n",
    "\n",
    "+ Add lags for variables Close and Adj_Close.\n",
    "+ Add returns based on Close:\n",
    "    \n",
    "    - `returns`: (Close / Close_lag_1) - 1\n",
    "\n",
    "+ Add the following range: \n",
    "\n",
    "    - `hi_lo_range`: this is the day's High minus Low.\n",
    "\n",
    "+ Assign the result to `dd_feat`.\n",
    "\n",
    "(4 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15199\\AppData\\Local\\Temp\\ipykernel_2180\\3633471738.py:8: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  df_lags = df.groupby('Ticker', group_keys=False).apply(\n",
      "C:\\Users\\15199\\AppData\\Local\\Temp\\ipykernel_2180\\3633471738.py:13: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  dd_feat = df_lags.groupby('Ticker', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Reading multiple parquet files into a Dask DataFrame\n",
    "df = dd.read_parquet(parquet_files)\n",
    "\n",
    "# Grouping by Ticker column and group_keys = False ensures that the group labels do not appear in the index of the result. \n",
    "# .apply() will apply the given function to each group. \n",
    "# lambda is the other way of defining a function. E.g .shift(1) will take the Close column value from the previous row and assign it to the new column name Close_lag_1.\n",
    "\n",
    "df_lags = df.groupby('Ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(Close_lag_1 = x['Close'].shift(1),\n",
    "                       Close_lag_2 = x['Adj Close'].shift(1))\n",
    ")\n",
    "\n",
    "dd_feat = df_lags.groupby('Ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(returns = (x['Close'] / x['Close_lag_1']) - 1,\n",
    "                       hi_lo_range = x['High'] - x['Low'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert the Dask data frame to a pandas data frame. \n",
    "+ Add a new feature containing the moving average of `returns` using a window of 10 days. There are several ways to solve this task, a simple one uses `.rolling(10).mean()`.\n",
    "\n",
    "(3 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Close_lag_1</th>\n",
       "      <th>Close_lag_2</th>\n",
       "      <th>returns</th>\n",
       "      <th>hi_lo_range</th>\n",
       "      <th>rolling_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>322016</th>\n",
       "      <td>2020-01-02 00:00:00+00:00</td>\n",
       "      <td>JNPR</td>\n",
       "      <td>21.375463</td>\n",
       "      <td>24.709999</td>\n",
       "      <td>24.900000</td>\n",
       "      <td>24.540001</td>\n",
       "      <td>24.809999</td>\n",
       "      <td>2876000.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322080</th>\n",
       "      <td>2020-01-03 00:00:00+00:00</td>\n",
       "      <td>JNPR</td>\n",
       "      <td>21.055395</td>\n",
       "      <td>24.340000</td>\n",
       "      <td>24.510000</td>\n",
       "      <td>24.170000</td>\n",
       "      <td>24.260000</td>\n",
       "      <td>3041800.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>24.709999</td>\n",
       "      <td>21.375463</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322144</th>\n",
       "      <td>2020-01-06 00:00:00+00:00</td>\n",
       "      <td>JNPR</td>\n",
       "      <td>21.012142</td>\n",
       "      <td>24.290001</td>\n",
       "      <td>24.410000</td>\n",
       "      <td>24.139999</td>\n",
       "      <td>24.160000</td>\n",
       "      <td>4141100.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>24.340000</td>\n",
       "      <td>21.055395</td>\n",
       "      <td>-0.002054</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322208</th>\n",
       "      <td>2020-01-07 00:00:00+00:00</td>\n",
       "      <td>JNPR</td>\n",
       "      <td>20.925638</td>\n",
       "      <td>24.190001</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>24.059999</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>1909500.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>24.290001</td>\n",
       "      <td>21.012142</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322272</th>\n",
       "      <td>2020-01-08 00:00:00+00:00</td>\n",
       "      <td>JNPR</td>\n",
       "      <td>20.856436</td>\n",
       "      <td>24.110001</td>\n",
       "      <td>24.320000</td>\n",
       "      <td>24.020000</td>\n",
       "      <td>24.129999</td>\n",
       "      <td>2143000.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>24.190001</td>\n",
       "      <td>20.925638</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225066</th>\n",
       "      <td>2013-12-24 00:00:00+00:00</td>\n",
       "      <td>NTAP</td>\n",
       "      <td>30.642590</td>\n",
       "      <td>40.380001</td>\n",
       "      <td>40.540001</td>\n",
       "      <td>40.279999</td>\n",
       "      <td>40.320000</td>\n",
       "      <td>1799900.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>40.380001</td>\n",
       "      <td>30.642590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260002</td>\n",
       "      <td>-0.002559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225130</th>\n",
       "      <td>2013-12-26 00:00:00+00:00</td>\n",
       "      <td>NTAP</td>\n",
       "      <td>30.589462</td>\n",
       "      <td>40.310001</td>\n",
       "      <td>40.660000</td>\n",
       "      <td>40.220001</td>\n",
       "      <td>40.220001</td>\n",
       "      <td>1862500.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>40.380001</td>\n",
       "      <td>30.642590</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.439999</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225194</th>\n",
       "      <td>2013-12-27 00:00:00+00:00</td>\n",
       "      <td>NTAP</td>\n",
       "      <td>30.885426</td>\n",
       "      <td>40.700001</td>\n",
       "      <td>40.810001</td>\n",
       "      <td>40.320000</td>\n",
       "      <td>40.330002</td>\n",
       "      <td>1943600.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>40.310001</td>\n",
       "      <td>30.589462</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.490002</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225258</th>\n",
       "      <td>2013-12-30 00:00:00+00:00</td>\n",
       "      <td>NTAP</td>\n",
       "      <td>31.097897</td>\n",
       "      <td>40.980000</td>\n",
       "      <td>41.090000</td>\n",
       "      <td>40.709999</td>\n",
       "      <td>40.730000</td>\n",
       "      <td>1918500.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>40.700001</td>\n",
       "      <td>30.885426</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.380001</td>\n",
       "      <td>0.003019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225322</th>\n",
       "      <td>2013-12-31 00:00:00+00:00</td>\n",
       "      <td>NTAP</td>\n",
       "      <td>31.219315</td>\n",
       "      <td>41.139999</td>\n",
       "      <td>41.439999</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.160000</td>\n",
       "      <td>1548000.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>40.980000</td>\n",
       "      <td>31.097897</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.439999</td>\n",
       "      <td>0.002756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403456 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date Ticker  Adj Close      Close       High  \\\n",
       "322016 2020-01-02 00:00:00+00:00   JNPR  21.375463  24.709999  24.900000   \n",
       "322080 2020-01-03 00:00:00+00:00   JNPR  21.055395  24.340000  24.510000   \n",
       "322144 2020-01-06 00:00:00+00:00   JNPR  21.012142  24.290001  24.410000   \n",
       "322208 2020-01-07 00:00:00+00:00   JNPR  20.925638  24.190001  24.400000   \n",
       "322272 2020-01-08 00:00:00+00:00   JNPR  20.856436  24.110001  24.320000   \n",
       "...                          ...    ...        ...        ...        ...   \n",
       "225066 2013-12-24 00:00:00+00:00   NTAP  30.642590  40.380001  40.540001   \n",
       "225130 2013-12-26 00:00:00+00:00   NTAP  30.589462  40.310001  40.660000   \n",
       "225194 2013-12-27 00:00:00+00:00   NTAP  30.885426  40.700001  40.810001   \n",
       "225258 2013-12-30 00:00:00+00:00   NTAP  31.097897  40.980000  41.090000   \n",
       "225322 2013-12-31 00:00:00+00:00   NTAP  31.219315  41.139999  41.439999   \n",
       "\n",
       "              Low       Open     Volume  Year  Close_lag_1  Close_lag_2  \\\n",
       "322016  24.540001  24.809999  2876000.0  2020          NaN          NaN   \n",
       "322080  24.170000  24.260000  3041800.0  2020    24.709999    21.375463   \n",
       "322144  24.139999  24.160000  4141100.0  2020    24.340000    21.055395   \n",
       "322208  24.059999  24.400000  1909500.0  2020    24.290001    21.012142   \n",
       "322272  24.020000  24.129999  2143000.0  2020    24.190001    20.925638   \n",
       "...           ...        ...        ...   ...          ...          ...   \n",
       "225066  40.279999  40.320000  1799900.0  2013    40.380001    30.642590   \n",
       "225130  40.220001  40.220001  1862500.0  2013    40.380001    30.642590   \n",
       "225194  40.320000  40.330002  1943600.0  2013    40.310001    30.589462   \n",
       "225258  40.709999  40.730000  1918500.0  2013    40.700001    30.885426   \n",
       "225322  41.000000  41.160000  1548000.0  2013    40.980000    31.097897   \n",
       "\n",
       "         returns  hi_lo_range  rolling_mean  \n",
       "322016       NaN     0.359999           NaN  \n",
       "322080 -0.014974     0.340000           NaN  \n",
       "322144 -0.002054     0.270000           NaN  \n",
       "322208 -0.004117     0.340000           NaN  \n",
       "322272 -0.003307     0.299999           NaN  \n",
       "...          ...          ...           ...  \n",
       "225066  0.000000     0.260002     -0.002559  \n",
       "225130 -0.001734     0.439999      0.000645  \n",
       "225194  0.009675     0.490002      0.002760  \n",
       "225258  0.006880     0.380001      0.003019  \n",
       "225322  0.003904     0.439999      0.002756  \n",
       "\n",
       "[403456 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Dask data frame to a pandas data frame. Further calculating moving average using a window of 10 days. First nine values will be NaN as there are not 10 values for the mean.\n",
    "dd_feat = dd_feat.compute()\n",
    "dd_feat['rolling_mean'] = dd_feat['returns'].rolling(10).mean()\n",
    "dd_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please comment:\n",
    "\n",
    "+ Was it necessary to convert to pandas to calculate the moving average return?\n",
    "+ Would it have been better to do it in Dask? Why?\n",
    "\n",
    "(1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ It's not necessary to convert to pandas to calculate the moving average return. We can also work with the csv files. Also, repartition() can be used with map_overlap() without converting Dask DataFrame to pandas for calculating the rolling average.  \n",
    "Dask DataFrame is lazy, meaning it doesn't compute results immediately. It does not show actual data; it just provides an overview. So, the other method is to use .compute() to show actual results to calculate the rolling average, and the compute method converts the dask DataFrame to pandas DataFrame. For data that fits into RAM, pandas can often be faster and easier to use than Dask DataFrame.  \n",
    "\n",
    "+ It depends on the size of the dataset. If it's small, pandas is the better than Dask. However, if it's large dataset, Dask is the best choice. Our dataset is not very large, so converting to pandas is good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_1_rubric_clean.xlsx) contains the criteria for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
